{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f71542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import pycpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import open3d as o3d\n",
    "import time\n",
    "import ast\n",
    "import h5py\n",
    "from ssm_utils import rotationMatrixToEulerAngles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "382de946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>srcObj</th>\n",
       "      <th>srcTxt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0L</td>\n",
       "      <td>./data/allData86Sample/caodongjuan_l.obj</td>\n",
       "      <td>./data/allData86Sample/caodongjuan_l.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0U</td>\n",
       "      <td>./data/allData86Sample/caodongjuan_u.obj</td>\n",
       "      <td>./data/allData86Sample/caodongjuan_u.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10L</td>\n",
       "      <td>./data/allData86Sample/caoxu_l.obj</td>\n",
       "      <td>./data/allData86Sample/caoxu_l.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10U</td>\n",
       "      <td>./data/allData86Sample/caoxu_u.obj</td>\n",
       "      <td>./data/allData86Sample/caoxu_u.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11L</td>\n",
       "      <td>./data/allData86Sample/axin_l.obj</td>\n",
       "      <td>./data/allData86Sample/axin_l.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag                                    srcObj  \\\n",
       "0   0L  ./data/allData86Sample/caodongjuan_l.obj   \n",
       "1   0U  ./data/allData86Sample/caodongjuan_u.obj   \n",
       "2  10L        ./data/allData86Sample/caoxu_l.obj   \n",
       "3  10U        ./data/allData86Sample/caoxu_u.obj   \n",
       "4  11L         ./data/allData86Sample/axin_l.obj   \n",
       "\n",
       "                                     srcTxt  \n",
       "0  ./data/allData86Sample/caodongjuan_l.txt  \n",
       "1  ./data/allData86Sample/caodongjuan_u.txt  \n",
       "2        ./data/allData86Sample/caoxu_l.txt  \n",
       "3        ./data/allData86Sample/caoxu_u.txt  \n",
       "4         ./data/allData86Sample/axin_l.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameIndexMapCSV = r\"./data/nameIndexMapping.csv\"\n",
    "dfNameIndexMap = pd.read_csv(nameIndexMapCSV)\n",
    "rowCount = dfNameIndexMap.shape[0]\n",
    "dfNameIndexMap.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0796decb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cutMesh</th>\n",
       "      <th>cutResult</th>\n",
       "      <th>toothMesh</th>\n",
       "      <th>auxiliaryInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87L</td>\n",
       "      <td>143123_cutMesh_L.obj</td>\n",
       "      <td>143123_cutResult_L.txt</td>\n",
       "      <td>143123_toothMesh_L.obj</td>\n",
       "      <td>143123_alignLoc_Dir_L.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87U</td>\n",
       "      <td>143123_cutMesh_U.obj</td>\n",
       "      <td>143123_cutResult_U.txt</td>\n",
       "      <td>143123_toothMesh_U.obj</td>\n",
       "      <td>143123_alignLoc_Dir_U.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88L</td>\n",
       "      <td>162065_cutMesh_L.obj</td>\n",
       "      <td>162065_cutResult_L.txt</td>\n",
       "      <td>162065_toothMesh_L.obj</td>\n",
       "      <td>162065_alignLoc_Dir_L.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88U</td>\n",
       "      <td>162065_cutMesh_U.obj</td>\n",
       "      <td>162065_cutResult_U.txt</td>\n",
       "      <td>162065_toothMesh_U.obj</td>\n",
       "      <td>162065_alignLoc_Dir_U.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89L</td>\n",
       "      <td>166779_cutMesh_L.obj</td>\n",
       "      <td>166779_cutResult_L.txt</td>\n",
       "      <td>166779_toothMesh_L.obj</td>\n",
       "      <td>166779_alignLoc_Dir_L.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag               cutMesh               cutResult               toothMesh  \\\n",
       "0  87L  143123_cutMesh_L.obj  143123_cutResult_L.txt  143123_toothMesh_L.obj   \n",
       "1  87U  143123_cutMesh_U.obj  143123_cutResult_U.txt  143123_toothMesh_U.obj   \n",
       "2  88L  162065_cutMesh_L.obj  162065_cutResult_L.txt  162065_toothMesh_L.obj   \n",
       "3  88U  162065_cutMesh_U.obj  162065_cutResult_U.txt  162065_toothMesh_U.obj   \n",
       "4  89L  166779_cutMesh_L.obj  166779_cutResult_L.txt  166779_toothMesh_L.obj   \n",
       "\n",
       "               auxiliaryInfo  \n",
       "0  143123_alignLoc_Dir_L.txt  \n",
       "1  143123_alignLoc_Dir_U.txt  \n",
       "2  162065_alignLoc_Dir_L.txt  \n",
       "3  162065_alignLoc_Dir_U.txt  \n",
       "4  166779_alignLoc_Dir_L.txt  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameIndexMapCSVSupp = r\"./data-refined/nameIndexMapping.csv\"\n",
    "suppDataDir = r\".\\data-refined\\repaired-txt\"\n",
    "suppStartIndex = 87 # indexing from 87U and 87L\n",
    "dfNameIndexMapSupp = pd.read_csv(nameIndexMapCSVSupp)\n",
    "rowCountSupp = dfNameIndexMapSupp.shape[0]\n",
    "dfNameIndexMapSupp[\"tag\"] = dfNameIndexMapSupp[\"tag\"].apply(lambda x:str(int(x[:-1])+suppStartIndex)+x[-1])\n",
    "dfNameIndexMapSupp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db75427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>srcObj</th>\n",
       "      <th>srcTxt</th>\n",
       "      <th>cutMesh</th>\n",
       "      <th>cutResult</th>\n",
       "      <th>toothMesh</th>\n",
       "      <th>auxiliaryInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0L</td>\n",
       "      <td>./data/allData86Sample/caodongjuan_l.obj</td>\n",
       "      <td>./data/allData86Sample/caodongjuan_l.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0U</td>\n",
       "      <td>./data/allData86Sample/caodongjuan_u.obj</td>\n",
       "      <td>./data/allData86Sample/caodongjuan_u.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10L</td>\n",
       "      <td>./data/allData86Sample/caoxu_l.obj</td>\n",
       "      <td>./data/allData86Sample/caoxu_l.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10U</td>\n",
       "      <td>./data/allData86Sample/caoxu_u.obj</td>\n",
       "      <td>./data/allData86Sample/caoxu_u.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11L</td>\n",
       "      <td>./data/allData86Sample/axin_l.obj</td>\n",
       "      <td>./data/allData86Sample/axin_l.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag                                    srcObj  \\\n",
       "0   0L  ./data/allData86Sample/caodongjuan_l.obj   \n",
       "1   0U  ./data/allData86Sample/caodongjuan_u.obj   \n",
       "2  10L        ./data/allData86Sample/caoxu_l.obj   \n",
       "3  10U        ./data/allData86Sample/caoxu_u.obj   \n",
       "4  11L         ./data/allData86Sample/axin_l.obj   \n",
       "\n",
       "                                     srcTxt cutMesh cutResult toothMesh  \\\n",
       "0  ./data/allData86Sample/caodongjuan_l.txt     NaN       NaN       NaN   \n",
       "1  ./data/allData86Sample/caodongjuan_u.txt     NaN       NaN       NaN   \n",
       "2        ./data/allData86Sample/caoxu_l.txt     NaN       NaN       NaN   \n",
       "3        ./data/allData86Sample/caoxu_u.txt     NaN       NaN       NaN   \n",
       "4         ./data/allData86Sample/axin_l.txt     NaN       NaN       NaN   \n",
       "\n",
       "  auxiliaryInfo  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将前后两次得到的数据合并\n",
    "dfNameIndexMapMerged = pd.merge(dfNameIndexMap, dfNameIndexMapSupp, how=\"outer\", on=\"tag\")\n",
    "rowCountTotal = dfNameIndexMapMerged.shape[0]\n",
    "assert rowCount + rowCountSupp == rowCountTotal\n",
    "dfNameIndexMapMerged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "921fe06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tooth row sample num: 138 upper, 138 lower.\n"
     ]
    }
   ],
   "source": [
    "# 分成上牙列和下压列\n",
    "__dfLowerToothRow = dfNameIndexMapMerged[dfNameIndexMapMerged[\"tag\"].apply(lambda x:x.upper()[-1]==\"L\")].copy()\n",
    "__dfUpperToothRow = dfNameIndexMapMerged[dfNameIndexMapMerged[\"tag\"].apply(lambda x:x.upper()[-1]==\"U\")].copy()\n",
    "print(\"Tooth row sample num: {} upper, {} lower.\".format(__dfUpperToothRow.shape[0],__dfLowerToothRow.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad9ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "RootDir = r\".\\data\\repaired-txt\"\n",
    "upperToothIndices = [11,12,13,14,15,16,17,21,22,23,24,25,26,27] #不考虑智齿18,28\n",
    "lowerToothIndices = [31,32,33,34,35,36,37,41,42,43,44,45,46,47] #不考虑智齿38,48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9c1b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getCentroidXYZ(row):\n",
    "    if not os.path.exists(row[\"tPath\"]):\n",
    "        return np.nan, np.nan, np.nan\n",
    "    else:\n",
    "        centroid = np.loadtxt(row[\"tPath\"]).mean(axis=0)\n",
    "        return centroid[0], centroid[1], centroid[2]\n",
    "\n",
    "CENTROID_START_INDEX = 7\n",
    "def createToothRowCentroidsDF(srcDir, UorL, toothIndices, dfNameIndexMap, centroidStartIndex=CENTROID_START_INDEX):\n",
    "    \"\"\"计算每颗牙齿的初始重心坐标，记录在csv中\"\"\"\n",
    "    dfToothRow = dfNameIndexMap[dfNameIndexMap[\"tag\"].apply(lambda x:x.upper()[-1]==UorL)].copy()\n",
    "    for uTId in toothIndices:\n",
    "        dfToothRow[\"tPath\"] = dfToothRow[\"tag\"].apply(lambda tag:os.path.join(srcDir,str(uTId),tag+\".txt\"))\n",
    "        newCols = [str(uTId)+\"x\",str(uTId)+\"y\",str(uTId)+\"z\"]\n",
    "        dfToothRow[newCols] = dfToothRow.apply(__getCentroidXYZ, axis=1, result_type=\"expand\")\n",
    "    dfToothRow.drop(columns=\"tPath\", inplace=True) #删除临时变量\n",
    "    dfToothRow = dfToothRow[~dfToothRow.iloc[:,centroidStartIndex:].isnull().all(axis=1)] #删除全空的行\n",
    "    dfToothRow.reset_index(drop=True, inplace=True)\n",
    "    return dfToothRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d98de5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "badInitDataIndices = {21:[\"65U\",],31:[\"43L\",\"85L\"],36:[\"83L\",\"84L\"]}\n",
    "# 需要跳过的补充数据（有缺陷的数据）\n",
    "badSuppDataIndices = {11:[17,25,31], 12:[20,39,7], 13:[10,12,15,28,33], 14:[15,36,39], 15:[33,35,36],\\\n",
    "                     16:[12,13,20,24,29,30,32,35,36,40,41,43,47,9], 17:[11,13,14,17,21,22,24,26,27,2,32,40,41,43,45,47,50,51,9],\\\n",
    "                     21:[7,], 22:[], 23:[5,25], 24:[20,25,33,48], 25:[20,25,48], 26:[19,33,43,48], 27:[19,20,24,25,3,8],\\\n",
    "                     31:[11,20,39,51], 32:[20,33,48,51], 33:[11,12,20,22,33,48,51], 34:[16,], 35:[32,], 36:[24,], 37:[11,20,50],\\\n",
    "                     41:[11,20,48,51], 42:[20,36], 43:[11,12,20,25,2,39], 44:[25,2,30,36], 45:[30,35], 46:[15,2,35,43], 47:[15,35,43]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a021549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileTagWithoutUL(f):\n",
    "    return int(os.path.basename(f).split(\".\")[0][:-1])\n",
    "\n",
    "def getFileUL(f):\n",
    "    return os.path.basename(f).split(\".\")[0][-1]\n",
    "\n",
    "# # Run it only once\n",
    "# # Merge suupplementary data into initial data\n",
    "# for tID,badIndices in badSuppDataIndices.items():\n",
    "#     allFiles = glob.glob(os.path.join(suppDataDir, str(tID), \"*.txt\"))\n",
    "#     normalFiles = [f for f in allFiles if getFileTagWithoutUL(f) not in badIndices]\n",
    "#     assert (len(allFiles) - len(normalFiles)) == len(badIndices)\n",
    "#     dstFiles = [os.path.join(RootDir,str(tID),str(getFileTagWithoutUL(f)+suppStartIndex)+getFileUL(f)+\".txt\") for f in normalFiles]\n",
    "#     for srcF,dstF in zip(normalFiles,dstFiles):\n",
    "#         assert getFileTagWithoutUL(dstF) - getFileTagWithoutUL(srcF) == suppStartIndex\n",
    "#         try:\n",
    "#             shutil.copy(srcF, dstF)\n",
    "#             # print(\"File copied successfully.\")\n",
    "#         # If source and destination are same\n",
    "#         except shutil.SameFileError:\n",
    "#             print(\"Source and destination represents the same file.\")\n",
    "#         # If there is any permission issue\n",
    "#         except PermissionError:\n",
    "#             print(\"Permission denied.\")\n",
    "#         # For other errors\n",
    "#         except:\n",
    "#             print(\"Error occurred while copying file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "477576b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "upperToothRowCentroidsCSV = r\"./data/upperToothRowCentroids.csv\"\n",
    "# dfUpperToothRow = createToothRowCentroidsDF(RootDir, \"U\", upperToothIndices, dfNameIndexMapMerged)\n",
    "# dfUpperToothRow.to_csv(upperToothRowCentroidsCSV,index=False)\n",
    "dfUpperToothRow = pd.read_csv(upperToothRowCentroidsCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c0dc809",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerToothRowCentroidsCSV = r\"./data/lowerToothRowCentroids.csv\"\n",
    "# dfLowerToothRow = createToothRowCentroidsDF(RootDir, \"L\", lowerToothIndices, dfNameIndexMapMerged)\n",
    "# dfLowerToothRow.to_csv(lowerToothRowCentroidsCSV,index=False)\n",
    "dfLowerToothRow = pd.read_csv(lowerToothRowCentroidsCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a8376aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfUpperToothRow.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0db19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getToothRowMeanCentroids(dfToothRow, toothIndices):\n",
    "    cols2ComputeMean = [str(id)+xyz for id in toothIndices for xyz in [\"x\",\"y\",\"z\"]] #[\"11x\",\"11y\",\"11z\",\"12x\",...]\n",
    "    return dfToothRow[cols2ComputeMean].mean(axis=0,skipna=True).to_numpy().reshape(-1,3)\n",
    "\n",
    "initMeanToothRow = getToothRowMeanCentroids(dfUpperToothRow, upperToothIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18ac7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOptimalRigidTransform(pRef,pMov):\n",
    "    \"\"\"已知pRef,pMov点的对应关系，计算最优刚性变换对应的旋转矩阵R和平移向量t\"\"\"\n",
    "    \"\"\"pRef.shape=(M,3) pMov.shape=(M,3): R,t = argmin 1/M * sum(||Qi @ R + t - Pi||_2)\"\"\"\n",
    "    assert pRef.shape == pMov.shape\n",
    "    meanP = pRef.mean(axis=0)\n",
    "    meanQ = pMov.mean(axis=0)\n",
    "    P = pRef - meanP\n",
    "    Q = pMov - meanQ\n",
    "    H = Q.T @ P # shape=(3,3)\n",
    "    u, s, vh = np.linalg.svd(H)\n",
    "    D = np.diag([1.,1.,np.linalg.det(u @ vh)])\n",
    "    R = u @ D @ vh\n",
    "    t = meanP - meanQ @ R\n",
    "    tpMov = pMov @ R + t\n",
    "    return R, t, tpMov\n",
    "\n",
    "def findOptimalIsoScaledRigidTransform(pRef,pMov):\n",
    "    \"\"\"已知pRef,pMov点的对应关系，计算最优缩放的刚性变换对应的缩放常数c,旋转矩阵R和平移向量t\"\"\"\n",
    "    \"\"\"pRef.shape=(M,3) pMov.shape=(M,3): R,t = argmin 1/M * sum(||Qi @ (c*R) + t - Pi||_2)\"\"\"\n",
    "    assert pRef.shape == pMov.shape\n",
    "    meanP = pRef.mean(axis=0)\n",
    "    meanQ = pMov.mean(axis=0)\n",
    "    P = pRef - meanP\n",
    "    Q = pMov - meanQ\n",
    "    n, dim = P.shape\n",
    "    H = 1./n * Q.T @ P # shape=(3,3)\n",
    "    u, s, vh = np.linalg.svd(H)\n",
    "    D = np.diag([1.,1.,np.linalg.det(u @ vh)])\n",
    "    R = u @ D @ vh\n",
    "    varQ = np.var(Q, axis=0).sum()\n",
    "    c = 1/varQ * np.sum(s) # scale factor\n",
    "    t = meanP - meanQ @ (c*R)\n",
    "    tpMov = pMov @ (c*R) + t\n",
    "    return c, R, t, tpMov\n",
    "\n",
    "def getRigidTransformError(pRef, pMov, R, t):\n",
    "    error = pMov @ R + t - pRef\n",
    "    return np.linalg.norm(error,ord=\"fro\")\n",
    "\n",
    "def getIsoScaledRigidTransformError(pRef, pMov, c, R, t):\n",
    "    error = pMov @ (c*R) + t - pRef\n",
    "    return np.linalg.norm(error,ord=\"fro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef6178e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rigid trans error:  6.482428508539035\n"
     ]
    }
   ],
   "source": [
    "pMov = dfUpperToothRow.iloc[1,7:].to_numpy().reshape(-1,3).astype(np.float64)\n",
    "pRef = initMeanToothRow\n",
    "R, t, _ = findOptimalRigidTransform(pRef,pMov)\n",
    "initError = getRigidTransformError(pRef, pMov, np.eye(3), np.array([0.,0.,0.]))\n",
    "finalError = getRigidTransformError(pRef, pMov, R, t)\n",
    "print(\"rigid trans error: \",finalError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c2ec98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso scaled rigid trans error:  6.211578011214068\n"
     ]
    }
   ],
   "source": [
    "s, R, t, _ = findOptimalIsoScaledRigidTransform(pRef,pMov)\n",
    "print(\"iso scaled rigid trans error: \", getIsoScaledRigidTransformError(pRef, pMov, s, R, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d642068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getToothRows(dfToothRow, toothIndices):\n",
    "    rowCount = dfToothRow.shape[0]\n",
    "    posCols = [str(id)+xyz for id in toothIndices for xyz in [\"x\",\"y\",\"z\"]]\n",
    "    toothRows = []\n",
    "    for i in range(rowCount):\n",
    "        pg = dfToothRow.loc[i,posCols].to_numpy().astype(np.float64).reshape(-1,3)\n",
    "        toothRows.append(pg)\n",
    "    return toothRows #toothRow may contain np.nan\n",
    "\n",
    "def getOptimalMeanToothRow(toothRows, relDiffEps, max_iter=10):\n",
    "    \"\"\"计算平均牙列每颗牙齿重心的位置\"\"\"\n",
    "    initMeanToothRow = np.nanmean(np.array(toothRows),axis=0)\n",
    "    rowCount = len(toothRows)\n",
    "    pMasks = [~np.isnan(x)[:,0] for x in toothRows]\n",
    "    alignedToothRows = [x.copy() for x in toothRows] #toothRow may contain np.nan\n",
    "    diff = np.inf\n",
    "    pRef = initMeanToothRow\n",
    "    prevPRef = pRef.copy()\n",
    "    iter = 0\n",
    "    while diff > relDiffEps and iter < max_iter:\n",
    "        iter += 1\n",
    "        print(\"iteration:{},diff:{}\".format(iter,diff))\n",
    "        for i in range(rowCount):\n",
    "            mask = pMasks[i]\n",
    "            pMov = alignedToothRows[i]\n",
    "            R, t, tpMov = findOptimalRigidTransform(pRef[mask,:],pMov[mask,:]) # 刚性配准\n",
    "            alignedToothRows[i][mask,:] = tpMov\n",
    "        pRef = np.nanmean(np.array(alignedToothRows),axis=0)\n",
    "        diff = np.linalg.norm(pRef-prevPRef, ord=\"fro\")/np.linalg.norm(pRef, ord=\"fro\")\n",
    "        prevPRef = pRef.copy()\n",
    "    return pRef\n",
    "\n",
    "def rePositionMeantoothRow(meanToothRow, isUpper=True):\n",
    "    \"\"\"将平均牙列的重心作为原点，重心到两颗第一切牙重心连线中心的方向为z轴正向，左侧最后一颗牙到右侧最后一颗牙重心的方向作为近似x轴，OZ叉乘近似x轴得出y轴，OY叉乘OZ得出x轴\"\"\"\n",
    "    \"\"\"meanToothRow.shape=(14,3) OR (16,3)\"\"\"\n",
    "    toothRow = meanToothRow.copy()\n",
    "    n, dim = meanToothRow.shape\n",
    "    OX = np.array([1.,0.,0.])\n",
    "    OY = np.array([0.,1.,0.])\n",
    "    OZ = np.array([0.,0.,1.])\n",
    "    meanCentroid = meanToothRow.mean(axis=0)\n",
    "    toothRow = toothRow - meanCentroid #原点平移至牙列重心\n",
    "    \n",
    "    firstLeftCentroid = meanToothRow[0,:] if isUpper else meanToothRow[n//2,:]\n",
    "    firstRightCentroid = meanToothRow[n//2,:] if isUpper else meanToothRow[0,:]\n",
    "    rotatedOZ = (firstLeftCentroid + firstRightCentroid)/2.0 - meanCentroid\n",
    "    rotatedOZ = rotatedOZ / np.linalg.norm(rotatedOZ, ord=2) #单位化\n",
    "    angle = np.arccos(np.dot(OZ, rotatedOZ))\n",
    "    rotAxis = np.cross(rotatedOZ, OZ)\n",
    "    rotAxis = rotAxis / np.linalg.norm(rotAxis, ord=2)\n",
    "    K = np.array([[0., -rotAxis[2], rotAxis[1]],\\\n",
    "        [rotAxis[2], 0., -rotAxis[0]],\\\n",
    "        [-rotAxis[1], rotAxis[0], 0.]])\n",
    "    LeftRotMat = np.identity(3) + np.sin(angle) * K + (1.-np.cos(angle)) * (K @ K)\n",
    "    RotMat = LeftRotMat.T\n",
    "    toothRow = toothRow @ RotMat #oz轴旋转至[0.,0.,1.]位置\n",
    "    \n",
    "    lastRightCentroid = meanToothRow[-1,:] if isUpper else meanToothRow[n//2-1,:]\n",
    "    lastLeftCentroid = meanToothRow[n//2-1,:] if isUpper else meanToothRow[-1,:]\n",
    "    approRotatedOX = lastRightCentroid - lastLeftCentroid\n",
    "    approRotatedOX = approRotatedOX / np.linalg.norm(approRotatedOX, ord=2) #单位化\n",
    "    rotatedOY = np.cross(rotatedOZ, approRotatedOX)\n",
    "    rotatedOY = rotatedOY @ RotMat[:3,:3]\n",
    "    rotatedOY = rotatedOY / np.linalg.norm(rotatedOY,ord=2)\n",
    "    \n",
    "    angle_ROZ = np.arccos(np.dot(OY, rotatedOY))\n",
    "    if np.cross(rotatedOY, OY)[2]<0:\n",
    "        angle_ROZ = -angle_ROZ\n",
    "    rotOZMat = np.array([[np.cos(angle_ROZ),np.sin(angle_ROZ),0.],[-np.sin(angle_ROZ),np.cos(angle_ROZ),0.],[0.,0.,1.]])\n",
    "    toothRow = toothRow @ rotOZMat\n",
    "    return toothRow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60f8793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignToothRows(pRef, toothRows):\n",
    "    scaleFactors = []\n",
    "    rotMatrices = []\n",
    "    transVecs = []\n",
    "    scaledAlignedToothRows = []\n",
    "    pMasks = [~np.isnan(x)[:,0] for x in toothRows]\n",
    "    for pMov,mask in zip(toothRows,pMasks):\n",
    "        s, R, t, tpMov = findOptimalIsoScaledRigidTransform(pRef[mask,:],pMov[mask,:])\n",
    "        scaleFactors.append(s)\n",
    "        rotMatrices.append(R)\n",
    "        transVecs.append(t)\n",
    "        tpMovGeneral = pMov.copy()\n",
    "        tpMovGeneral[mask,:] = tpMov\n",
    "        scaledAlignedToothRows.append(tpMovGeneral)\n",
    "    return scaledAlignedToothRows, scaleFactors, rotMatrices, transVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79d1d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransVecPerTooth(initToothRow, s, R, t):\n",
    "    \"\"\"将牙列比例缩放换算成每颗牙齿重心的位移\"\"\"\n",
    "    scaledAlignedToothRow = initToothRow * s @ R + t\n",
    "    ts = scaledAlignedToothRow - initToothRow @ R\n",
    "    return list(ts) # List of translation vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28b1f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = getTransVecPerTooth(upperToothRows[0], scaleFactors[0], rotMatrices[0], transVecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae7ef59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# err = upperToothRows[0]*scaleFactors[0]@rotMatrices[0]+transVecs[0] - scaledAlignedUpperToothRows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfdb07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getToothPointGroups(tag, srcDir, toothIndices):\n",
    "    \"\"\"按照toothIndices顺序读取tag对应的每颗牙齿的点云\"\"\"\n",
    "    pgFiles = [os.path.join(srcDir,str(tID),tag+\".txt\") for tID in toothIndices]\n",
    "    existFlags = [os.path.exists(f) for f in pgFiles]\n",
    "    pgs = [np.loadtxt(f) if os.path.exists(f) else np.nan for f in pgFiles]\n",
    "    return pgs, existFlags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeed83a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createToothPGsForSSA(dfToothRow, toothIndices, srcDir, saveDir, rotMatrices, LstTransVecs):\n",
    "    \"\"\"创建牙列位置调整后的repaired-txt用于SSA\"\"\"\n",
    "    for tID in toothIndices:\n",
    "        tDirPath = os.path.join(saveDir, str(tID))\n",
    "        if os.path.exists(tDirPath):\n",
    "            shutil.rmtree(tDirPath)\n",
    "        os.makedirs(tDirPath)\n",
    "    for tag,R,ts in zip(dfToothRow[\"tag\"], rotMatrices, LstTransVecs):\n",
    "        pgs, existFlags = getToothPointGroups(tag, srcDir, toothIndices)\n",
    "        for i,tID in enumerate(toothIndices):\n",
    "            if existFlags[i] == True:\n",
    "                assert not np.isnan(ts[i]).any()\n",
    "                ssaPG = pgs[i] @ R + ts[i]\n",
    "                saveTxtFile = os.path.join(saveDir, str(tID), tag+\".txt\")\n",
    "                np.savetxt(saveTxtFile, ssaPG)\n",
    "        print(\"Finish tag: \", tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33e7f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRotAngles(RotMats):\n",
    "    return np.vstack([rotationMatrixToEulerAngles(R) for R in RotMats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7623c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = r\".\\data\\ssa-repaired-txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b3a6eac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:1,diff:inf\n",
      "iteration:2,diff:0.004058913229208649\n"
     ]
    }
   ],
   "source": [
    "upperToothRows = getToothRows(dfUpperToothRow, upperToothIndices)\n",
    "refUpperToothRow = getOptimalMeanToothRow(upperToothRows, relDiffEps=1e-4, max_iter=5)\n",
    "refUpperToothRow = rePositionMeantoothRow(refUpperToothRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1716323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.20844334e+00, -1.39570095e-02,  1.60582868e+01],\n",
       "       [-1.09311250e+01,  1.22465801e-02,  1.34761320e+01],\n",
       "       [-1.64413870e+01,  1.34486705e-01,  8.97654833e+00],\n",
       "       [-1.90016411e+01, -4.64979556e-01,  1.92256133e+00],\n",
       "       [-2.13038706e+01, -6.28126138e-01, -4.66279398e+00],\n",
       "       [-2.36116641e+01, -8.86136200e-02, -1.30583565e+01],\n",
       "       [-2.68440575e+01,  1.16720277e+00, -2.23780560e+01],\n",
       "       [ 4.20844334e+00,  1.39570095e-02,  1.61217485e+01],\n",
       "       [ 1.10078346e+01,  6.02790942e-03,  1.32358781e+01],\n",
       "       [ 1.64929144e+01,  1.62590231e-01,  8.81046786e+00],\n",
       "       [ 1.90313648e+01, -5.17552391e-01,  1.79920271e+00],\n",
       "       [ 2.14624633e+01, -7.56940572e-01, -4.68908068e+00],\n",
       "       [ 2.35358350e+01, -1.93544697e-01, -1.30909899e+01],\n",
       "       [ 2.66033333e+01,  1.16720277e+00, -2.25215486e+01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refUpperToothRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23fb66a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaledAlignedUpperToothRows, upperScaleFactors, upperRotMatrices, initUpperTransVecs = alignToothRows(refUpperToothRow, upperToothRows) # toothRows may contain nan values\n",
    "LstUpperTransVecs = [getTransVecPerTooth(toothRow,s,R,t) for toothRow,s,R,t in zip(upperToothRows,upperScaleFactors, upperRotMatrices, initUpperTransVecs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ca87fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveToothRowScales2Hdf5(h5File, UorL, scales, transVecShifts, tags):\n",
    "    \"\"\"根据tags保存对应的sRtParams\"\"\"\n",
    "    if not os.path.exists(os.path.dirname(h5File)):\n",
    "        os.makedirs(os.path.dirname(h5File))\n",
    "    encodedTags = [tag.encode() for tag in tags]\n",
    "    scales = list(scales)\n",
    "    with h5py.File(h5File,'w') as f: #每次覆盖写入\n",
    "        grp = f.create_group(\"toothRow{}\".format(UorL))\n",
    "        grp.create_dataset(\"tag\", data=encodedTags)\n",
    "        grp.create_dataset(\"s\", data=np.array(scales, dtype=np.double))\n",
    "        grp.create_dataset(\"ts\", data=np.array(transVecShifts, dtype=np.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "296b202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "upperTransVecShifts = np.array(LstUpperTransVecs)-np.array(initUpperTransVecs)[:,np.newaxis,:]\n",
    "saveToothRowScales2Hdf5(r\"./data/params/scalesOfUpperToothRow.hdf5\", \"U\", upperScaleFactors, upperTransVecShifts, dfUpperToothRow[\"tag\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4f6d903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean scale: 0.9990334386316926\n",
      "max scale: 1.177237543865566\n",
      "min scale: 0.8724790296207059\n",
      "Std dev of scale: 0.05101920065347013\n",
      "mean rotation XYZ angles:  [ 0.03975428  0.00144847 -0.00029261]\n",
      "max rotation XYZ angles:  [0.15847298 0.07871443 0.0839845 ]\n",
      "min rotation XYZ angles:  [-0.03532782 -0.12692128 -0.05095244]\n",
      "Std dev of rotation XYZ angles:  [0.02502459 0.02770015 0.02056212]\n"
     ]
    }
   ],
   "source": [
    "print(\"mean scale:\",np.array(upperScaleFactors).mean())\n",
    "print(\"max scale:\",np.array(upperScaleFactors).max())\n",
    "print(\"min scale:\",np.array(upperScaleFactors).min())\n",
    "print(\"Std dev of scale:\",np.sqrt(np.var(np.array(upperScaleFactors))))\n",
    "rotAnglesXYZ = getRotAngles(upperRotMatrices)\n",
    "print(\"mean rotation XYZ angles: \",rotAnglesXYZ.mean(axis=0))\n",
    "print(\"max rotation XYZ angles: \",rotAnglesXYZ.max(axis=0))\n",
    "print(\"min rotation XYZ angles: \",rotAnglesXYZ.min(axis=0))\n",
    "print(\"Std dev of rotation XYZ angles: \",np.sqrt(np.var(rotAnglesXYZ, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57904a4a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# createToothPGsForSSA(dfUpperToothRow, upperToothIndices, RootDir, SAVE_DIR, upperRotMatrices, LstUpperTransVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b3a4ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:1,diff:inf\n",
      "iteration:2,diff:0.0035529545833956067\n"
     ]
    }
   ],
   "source": [
    "lowerToothRows = getToothRows(dfLowerToothRow, lowerToothIndices)\n",
    "refLowerToothRow = getOptimalMeanToothRow(lowerToothRows, relDiffEps=1e-4, max_iter=5)\n",
    "refLowerToothRow = rePositionMeantoothRow(refLowerToothRow, isUpper=False)\n",
    "scaledAlignedLowerToothRows, lowerScaleFactors, lowerRotMatrices, initLowerTransVecs = alignToothRows(refLowerToothRow, lowerToothRows) # toothRows may contain nan values\n",
    "LstLowerTransVecs = [getTransVecPerTooth(toothRow,s,R,t) for toothRow,s,R,t in zip(lowerToothRows,lowerScaleFactors, lowerRotMatrices, initLowerTransVecs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbb7da73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.55308229,  -0.04933793,  13.21976399],\n",
       "       [  7.50882884,  -0.14616313,  11.92186826],\n",
       "       [ 12.55902392,  -0.82403485,   8.84114069],\n",
       "       [ 16.7262011 ,  -0.85933367,   3.3675755 ],\n",
       "       [ 19.28316663,  -0.53563296,  -3.18921899],\n",
       "       [ 22.04626265,   0.16846391, -11.91730412],\n",
       "       [ 24.89497277,   1.92800724, -22.25896229],\n",
       "       [ -2.55308229,   0.04933793,  13.09277301],\n",
       "       [ -7.604399  ,  -0.07014801,  11.88176521],\n",
       "       [-12.601942  ,  -0.71109559,   8.87045761],\n",
       "       [-16.81523202,  -0.71347926,   3.44777064],\n",
       "       [-19.18329398,  -0.41270419,  -3.18663556],\n",
       "       [-21.9254979 ,   0.24811326, -11.88980949],\n",
       "       [-24.88809102,   1.92800724, -22.20118445]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refLowerToothRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac46fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerTransVecShifts = np.array(LstLowerTransVecs)-np.array(initLowerTransVecs)[:,np.newaxis,:]\n",
    "saveToothRowScales2Hdf5(r\"./data/params/scalesOfLowerToothRow.hdf5\", \"L\", lowerScaleFactors, lowerTransVecShifts, dfLowerToothRow[\"tag\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd044112",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# createToothPGsForSSA(dfLowerToothRow, lowerToothIndices, RootDir, SAVE_DIR, lowerRotMatrices, LstLowerTransVecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc23f6",
   "metadata": {},
   "source": [
    "## Tooth Row Alignment for tooth data in folder ./dataWithPhoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abd96856",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = r\"./dataWithPhoto\"\n",
    "REP_TXT_DIR = os.path.join(DATASET_DIR, \"repaired-txt\")\n",
    "SSA_REP_TXT_DIR = os.path.join(DATASET_DIR, \"ssa-repaired-txt\")\n",
    "NAME_INDEX_MAPPING_CSV = os.path.join(DATASET_DIR,\"nameIndexMapping.csv\")\n",
    "UPPER_CENTROIDS_CSV = os.path.join(DATASET_DIR,\"upperToothRowCentroids.csv\")\n",
    "LOWER_CENTROIDS_CSV = os.path.join(DATASET_DIR,\"lowerToothRowCentroids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bde30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "infoDF = pd.read_csv(NAME_INDEX_MAPPING_CSV)\n",
    "infoDF.rename(columns={'tag':'uniqueIndex','index':'tag'},inplace=True) \n",
    "upperToothRowDF = infoDF.copy()\n",
    "upperToothRowDF[\"tag\"] = upperToothRowDF[\"tag\"].apply(lambda x:\"{}{}\".format(x,\"U\"))\n",
    "lowerToothRowDF = infoDF.copy()\n",
    "lowerToothRowDF[\"tag\"] = lowerToothRowDF[\"tag\"].apply(lambda x:\"{}{}\".format(x,\"L\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c96603bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 计算上牙列中心位置，储存到csv\n",
    "# upperToothRowDF = createToothRowCentroidsDF(REP_TXT_DIR, \"U\", upperToothIndices, upperToothRowDF, centroidStartIndex=15)\n",
    "# upperToothRowDF.to_csv(UPPER_CENTROIDS_CSV,index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4efab00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 计算下牙列中心位置，储存到csv\n",
    "# lowerToothRowDF = createToothRowCentroidsDF(REP_TXT_DIR, \"L\", lowerToothIndices, lowerToothRowDF, centroidStartIndex=15)\n",
    "# lowerToothRowDF.to_csv(LOWER_CENTROIDS_CSV,index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b29d633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "upperToothRowDF = pd.read_csv(UPPER_CENTROIDS_CSV)\n",
    "lowerToothRowDF = pd.read_csv(LOWER_CENTROIDS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df94c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "upperToothRowCentroids = getToothRows(upperToothRowDF, upperToothIndices)\n",
    "# refUpperToothRow 前面已经计算过了\n",
    "_scaledAlignedUpperToothRows, _upperScaleFactors, _upperRotMatrices, _initUpperTransVecs = alignToothRows(refUpperToothRow, upperToothRowCentroids) # toothRows may contain nan values\n",
    "_LstUpperTransVecs = [getTransVecPerTooth(toothRow,s,R,t) for toothRow,s,R,t in zip(upperToothRowCentroids,_upperScaleFactors, _upperRotMatrices, _initUpperTransVecs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2f87d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.41047784   0.05925293  16.60700087]\n",
      " [-11.9949762    0.14564512  12.65740195]\n",
      " [-17.63094371  -0.61176257   7.17804135]\n",
      " [-20.10944126  -0.45467647  -0.58786907]\n",
      " [         nan          nan          nan]\n",
      " [-23.22052291   0.11969689 -10.12870044]\n",
      " [-28.47623391   1.18551167 -20.00626531]\n",
      " [  5.039876     0.50449897  16.64559708]\n",
      " [ 11.46328379   0.17569814  11.58091708]\n",
      " [ 17.10004855  -0.1006173    6.51758783]\n",
      " [ 19.98651216  -0.40582477  -0.70345755]\n",
      " [         nan          nan          nan]\n",
      " [ 23.16668763  -0.08734769 -10.46838871]\n",
      " [ 28.92759501   0.8549918  -19.93999041]] 1.1274584067568585 [[ 9.92242332e-01  9.25938901e-03 -1.23973462e-01]\n",
      " [ 2.95941731e-04  9.97043678e-01  7.68362926e-02]\n",
      " [ 1.24318414e-01 -7.62769111e-02  9.89306204e-01]] [-0.69333245 -2.4671092  -6.47563472]\n"
     ]
    }
   ],
   "source": [
    "print(_scaledAlignedUpperToothRows[0],_upperScaleFactors[0],_upperRotMatrices[0],_initUpperTransVecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d516a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_upperTransVecShifts = np.array(_LstUpperTransVecs)-np.array(_initUpperTransVecs)[:,np.newaxis,:]\n",
    "saveToothRowScales2Hdf5(os.path.join(DATASET_DIR, \"params\",\"scalesOfUpperToothRow.hdf5\"), \"U\", _upperScaleFactors, _upperTransVecShifts, upperToothRowDF[\"tag\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38e13f1c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish tag:  0U\n",
      "Finish tag:  1U\n",
      "Finish tag:  2U\n",
      "Finish tag:  3U\n",
      "Finish tag:  4U\n",
      "Finish tag:  5U\n",
      "Finish tag:  6U\n",
      "Finish tag:  7U\n",
      "Finish tag:  8U\n",
      "Finish tag:  9U\n",
      "Finish tag:  10U\n",
      "Finish tag:  11U\n",
      "Finish tag:  12U\n",
      "Finish tag:  13U\n",
      "Finish tag:  14U\n",
      "Finish tag:  15U\n",
      "Finish tag:  16U\n",
      "Finish tag:  17U\n",
      "Finish tag:  18U\n",
      "Finish tag:  19U\n",
      "Finish tag:  20U\n",
      "Finish tag:  21U\n",
      "Finish tag:  22U\n",
      "Finish tag:  23U\n",
      "Finish tag:  24U\n",
      "Finish tag:  25U\n",
      "Finish tag:  26U\n",
      "Finish tag:  27U\n",
      "Finish tag:  28U\n",
      "Finish tag:  29U\n",
      "Finish tag:  30U\n",
      "Finish tag:  31U\n",
      "Finish tag:  32U\n",
      "Finish tag:  33U\n",
      "Finish tag:  34U\n",
      "Finish tag:  35U\n",
      "Finish tag:  36U\n",
      "Finish tag:  37U\n",
      "Finish tag:  38U\n",
      "Finish tag:  39U\n",
      "Finish tag:  40U\n",
      "Finish tag:  41U\n",
      "Finish tag:  42U\n",
      "Finish tag:  43U\n",
      "Finish tag:  44U\n",
      "Finish tag:  45U\n",
      "Finish tag:  46U\n",
      "Finish tag:  47U\n",
      "Finish tag:  48U\n",
      "Finish tag:  49U\n",
      "Finish tag:  50U\n",
      "Finish tag:  51U\n",
      "Finish tag:  52U\n",
      "Finish tag:  53U\n",
      "Finish tag:  54U\n",
      "Finish tag:  55U\n",
      "Finish tag:  56U\n",
      "Finish tag:  57U\n",
      "Finish tag:  58U\n",
      "Finish tag:  59U\n",
      "Finish tag:  60U\n",
      "Finish tag:  61U\n",
      "Finish tag:  62U\n",
      "Finish tag:  63U\n",
      "Finish tag:  64U\n",
      "Finish tag:  65U\n",
      "Finish tag:  66U\n",
      "Finish tag:  67U\n",
      "Finish tag:  68U\n",
      "Finish tag:  69U\n",
      "Finish tag:  70U\n",
      "Finish tag:  71U\n",
      "Finish tag:  72U\n",
      "Finish tag:  73U\n",
      "Finish tag:  74U\n",
      "Finish tag:  75U\n",
      "Finish tag:  76U\n",
      "Finish tag:  77U\n",
      "Finish tag:  78U\n",
      "Finish tag:  79U\n",
      "Finish tag:  80U\n",
      "Finish tag:  81U\n",
      "Finish tag:  82U\n",
      "Finish tag:  83U\n",
      "Finish tag:  84U\n",
      "Finish tag:  85U\n",
      "Finish tag:  86U\n",
      "Finish tag:  87U\n",
      "Finish tag:  88U\n",
      "Finish tag:  89U\n",
      "Finish tag:  90U\n",
      "Finish tag:  91U\n",
      "Finish tag:  92U\n",
      "Finish tag:  93U\n",
      "Finish tag:  94U\n"
     ]
    }
   ],
   "source": [
    "createToothPGsForSSA(upperToothRowDF, upperToothIndices, srcDir=REP_TXT_DIR, saveDir=SSA_REP_TXT_DIR, rotMatrices=_upperRotMatrices, LstTransVecs=_LstUpperTransVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4bc9251",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerToothRowCentroids = getToothRows(lowerToothRowDF, lowerToothIndices)\n",
    "# refLowerToothRow 前面已经计算过了\n",
    "_scaledAlignedLowerToothRows, _lowerScaleFactors, _lowerRotMatrices, _initLowerTransVecs = alignToothRows(refLowerToothRow, lowerToothRowCentroids) # toothRows may contain nan values\n",
    "_LstLowerTransVecs = [getTransVecPerTooth(toothRow,s,R,t) for toothRow,s,R,t in zip(lowerToothRowCentroids,_lowerScaleFactors, _lowerRotMatrices, _initLowerTransVecs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea43a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_lowerTransVecShifts = np.array(_LstLowerTransVecs)-np.array(_initLowerTransVecs)[:,np.newaxis,:]\n",
    "saveToothRowScales2Hdf5(os.path.join(DATASET_DIR, \"params\",\"scalesOfLowerToothRow.hdf5\"), \"L\", _lowerScaleFactors, _lowerTransVecShifts, lowerToothRowDF[\"tag\"].to_list())\n",
    "saveToothRowScales2Hdf5(os.path.join(DATASET_DIR, \"cpdGpParams\",\"scalesOfLowerToothRow.hdf5\"), \"L\", _lowerScaleFactors, _lowerTransVecShifts, lowerToothRowDF[\"tag\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f1d5b1e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish tag:  0L\n",
      "Finish tag:  1L\n",
      "Finish tag:  2L\n",
      "Finish tag:  3L\n",
      "Finish tag:  4L\n",
      "Finish tag:  5L\n",
      "Finish tag:  6L\n",
      "Finish tag:  7L\n",
      "Finish tag:  8L\n",
      "Finish tag:  9L\n",
      "Finish tag:  10L\n",
      "Finish tag:  11L\n",
      "Finish tag:  12L\n",
      "Finish tag:  13L\n",
      "Finish tag:  14L\n",
      "Finish tag:  15L\n",
      "Finish tag:  16L\n",
      "Finish tag:  17L\n",
      "Finish tag:  18L\n",
      "Finish tag:  19L\n",
      "Finish tag:  20L\n",
      "Finish tag:  21L\n",
      "Finish tag:  22L\n",
      "Finish tag:  23L\n",
      "Finish tag:  24L\n",
      "Finish tag:  25L\n",
      "Finish tag:  26L\n",
      "Finish tag:  27L\n",
      "Finish tag:  28L\n",
      "Finish tag:  29L\n",
      "Finish tag:  30L\n",
      "Finish tag:  31L\n",
      "Finish tag:  32L\n",
      "Finish tag:  33L\n",
      "Finish tag:  34L\n",
      "Finish tag:  35L\n",
      "Finish tag:  36L\n",
      "Finish tag:  37L\n",
      "Finish tag:  38L\n",
      "Finish tag:  39L\n",
      "Finish tag:  40L\n",
      "Finish tag:  41L\n",
      "Finish tag:  42L\n",
      "Finish tag:  43L\n",
      "Finish tag:  44L\n",
      "Finish tag:  45L\n",
      "Finish tag:  46L\n",
      "Finish tag:  47L\n",
      "Finish tag:  48L\n",
      "Finish tag:  49L\n",
      "Finish tag:  50L\n",
      "Finish tag:  51L\n",
      "Finish tag:  52L\n",
      "Finish tag:  53L\n",
      "Finish tag:  54L\n",
      "Finish tag:  55L\n",
      "Finish tag:  56L\n",
      "Finish tag:  57L\n",
      "Finish tag:  58L\n",
      "Finish tag:  59L\n",
      "Finish tag:  60L\n",
      "Finish tag:  61L\n",
      "Finish tag:  62L\n",
      "Finish tag:  63L\n",
      "Finish tag:  64L\n",
      "Finish tag:  65L\n",
      "Finish tag:  66L\n",
      "Finish tag:  67L\n",
      "Finish tag:  68L\n",
      "Finish tag:  69L\n",
      "Finish tag:  70L\n",
      "Finish tag:  71L\n",
      "Finish tag:  72L\n",
      "Finish tag:  73L\n",
      "Finish tag:  74L\n",
      "Finish tag:  75L\n",
      "Finish tag:  76L\n",
      "Finish tag:  77L\n",
      "Finish tag:  78L\n",
      "Finish tag:  79L\n",
      "Finish tag:  80L\n",
      "Finish tag:  81L\n",
      "Finish tag:  82L\n",
      "Finish tag:  83L\n",
      "Finish tag:  84L\n",
      "Finish tag:  85L\n",
      "Finish tag:  86L\n",
      "Finish tag:  87L\n",
      "Finish tag:  88L\n",
      "Finish tag:  89L\n",
      "Finish tag:  90L\n",
      "Finish tag:  91L\n",
      "Finish tag:  92L\n",
      "Finish tag:  93L\n",
      "Finish tag:  94L\n"
     ]
    }
   ],
   "source": [
    "createToothPGsForSSA(lowerToothRowDF, lowerToothIndices, srcDir=REP_TXT_DIR, saveDir=SSA_REP_TXT_DIR, rotMatrices=_lowerRotMatrices, LstTransVecs=_LstLowerTransVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67f1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb736fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ssa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "688b9b30839bfaf806a86a795381ff2a51bf54ef46e418cbf12e72d6fb1893fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
